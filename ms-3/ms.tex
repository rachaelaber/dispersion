\documentclass[11pt,letterpaper]{article}


% Packages
\usepackage{authblk} % author affiliations
\usepackage{graphicx} % graphics
\usepackage{amsmath, amssymb} % mathematical symbols
\usepackage{natbib} % bibliography
\usepackage[margin=1in]{geometry} % margins
\usepackage{lineno} % line numbers
\usepackage{setspace} % linespacing
\usepackage{hyperref} % For hyperlinks

% Set 1.5 spacing
\setstretch{1.5}


% Set citation style
\setcitestyle{numbers} 

% Metadata
\title{Time-series modeling of epidemics in complex populations: detecting changes in incidence volatility over time}
\author[1]{Rachael Aber}
\author[2]{Yanming Di}
\author[1,3]{Benjamin D. Dalziel}
\affil[1]{Department of Integrative Biology, Oregon State University, Corvallis, Oregon, USA}
\affil[2]{Department of Statistics, Oregon, Oregon State University, Corvallis, Oregon, USA}
\affil[3]{Department of Mathematics, Oregon State University, Corvallis, Oregon, USA}
\date{} % No date for submissions

% Begin Document
\begin{document}

\linenumbers\maketitle

\begin{abstract}
Trends in infectious disease incidence provide important information about epidemic dynamics and prospects for control. 
Higher-frequency variation around incidence trends can shed light on the processes driving epidemics in complex populations, as transmission heterogeneity, shifting landscapes of susceptibility, and fluctuations in reporting can impact the volatility of observed case counts.
However, measures of temporal volatility in incidence, and how volatility changes over time, are often overlooked in population-level analyses of incidence data, which typically focus on moving averages.
Here we present a statistical framework to quantify temporal changes in incidence dispersion and detect rapid shifts in the dispersion parameter, which may signal new epidemic phases. 
We apply the method to COVID-19 incidence data in 144 United States (US) counties from the January 1st, 2020 to March 23rd, 2023.
Theory predicts that dispersion should be inversely proportional to incidence, however our method reveals pronounced temporal trends in dispersion that are not explained by incidence alone, but which are replicated across counties. 
In particular, dispersion increased around the major surge in cases in 2022, and highly overdispersed patterns became more frequent later in the time series.
These findings suggest that heterogeneity in transmission, susceptibility, and reporting could play important roles in driving large surges and extending epidemic duration. 
The dispersion of incidence time series can contain structured information which enhances predictive understanding of the underlying drivers of transmission, with potential applications as leading indicators for public health response.
\end{abstract}

\clearpage
\section*{Author summary}
Understanding patterns in infectious disease incidence is crucial for understanding epidemic dynamics and for developing effective public Traditional metrics used to quantify incidence patterns often overlook variability as an important characteristic of incidence time series. 
Quantifying variability around incidence trends can elucidate important underlying processes, including transmission heterogeneity.
We developed a statistical framework to quantify temporal changes in case count dispersion within a single time series and applied the method to COVID-19 case count data. 
We found that conspicuous shifts in dispersion occurred across counties concurrently, and that these shifts were not explained by incidence alone. 
Dispersion increased around peaks in incidence such as the major surge in cases in 2022, and dispersion also increased as the pandemic progressed. 
These increases potentially indicate transmission heterogeneity, changes in the susceptibility landscape, or that there were changes in reporting.
Shifts in dispersion can also indicate shifts in epidemic phase, so our method provides a way for public health officials to anticipate and manage changes in epidemic regime and the drivers of transmission. 

\clearpage
\section*{Introduction}
Time series of infectious disease incidence appear, to varying degrees, ``noisy'', showing higher frequency fluctuations (e.g., day-to-day or week-to-week fluctations) around trends at the broader temporal ranges typical for epidemic curves (e.g., months or years).
Short-term fluctuations in incidence time series are caused in part by variable reporting, but may also reflect the population-level impacts of transmission heterogeneity, and changes in the landscape of susceptiblility~\citep{lloyd2005superspreading,lloyd2007maximum, lau2017spatial, dalziel2018urbanization, kirkegaard2021superspreading, sun2021transmission,guo2023statistical,ko2023time}.
Metrics of variability in incidence time series may therefore carry information regarding underlying drivers of transmission, and offer a relatively unexplored avenue for understanding epidemic dynamics. 

Contact tracing data has revealed temporal changes in the variability of individual reproductive numbers, quantified by shifts in the dispersion parameter of the offspring distribution in branching process models~\citep{guo2023statistical,ko2023time}. 
Similar evidence has been recovered through statistical reconstruction of transmission networks, indicating temporal trends in the level of dispersion at different phases of an epidemic~\citep{lau2017spatial}.
However, the scaling from individual-level transmission heterogeneity to population-level epidemic dynamics is not fully understood.
In addition, traditional contact tracing is very resource intensive, and although new approaches using digital technologies may improve its speed and scalability~\citep{kretzschmar2020impact}, it would be helpful to have complementary population-level analyses that can estimate heterogeneity using incidence data, which is more widely available.
The importance of considering population-level variability and its relationship to individual-level variability is further highlighted by the finding that a combination of individual-based and population-based strategies were required for SARS-CoV-2 control during the early phases of the pandemic in China~\citep{sun2021transmission}. 
An important challenge therefore is to develop methods that can detect changes in population-level variability in incidence time series, and to interpret these changes in terms of underlying transmission processes.

Emerging statistical techniques are leveraging variability in epidemic time series to enhance understanding of disease dynamics at the population level. 
For example, a recently-developed method uses population-level incidence data to the dispersion parameter of the offspring distribution, which quantifies heterogeneity in secondary cases generated by an infected individual~\citep{kirkegaard2021superspreading}. 
It is also possible to estimate the dispersion parameter from the distribution of the final size of a series of localized outbreaks~\citep{blumberg2013inference}.
Clustering of cases has also been estimated directly from incidence data~\citep{schneckenreither2023assessing}.
Another important application links variability in incidence to epidemic phases; for example, changes in the mean and interannual coefficient of variation of measles incidence have been used to identify a country’s position on the path to elimination, providing insights into vaccination strategies and epidemiological dynamics~\citep{graham2019measles}. 
Analysis of the shape of epidemic curves for influenza in cities may identify contexts where incidence is focussed more intensely (proportionally more infections in a smaller span of time) with implications on the sensitivity of cities to climate forcing and for surge capacity in the health system~\citep{dalziel2018urbanization, wallinga2018metropolitan}. 

What drives indicence dispersion and how does it relate to the underlying branching process of transmission, and to observations of cases? 
Under a wide range of configurations for a branching process model of contagion spread, the number of infected individuals $I_t$ at time $t$ will have a negative binomial distribution~\citep{kendall1949stochastic, grenfell2002dynamics}, $I_t \sim NB \left( \mu_t, \theta_t \right)$, where $\mu_t$ is the expectation for $I_t$ and $\theta_t$ is the dispersion parameter. 
The variance is related to the mean and dispersion parameters by $\mathrm{Var}[I_t] = \mu_t + \mu_t^2 / \theta_t$, so smaller values of the dispersion parameter $\theta_t$ correspond to increasing amounts of dispersion, which increase the amounts by which the variance in realized number infected $I_t$ exceeds the expected value, $\mu_t$. 
Conversely, the distribution of $I_t$ tends to a Poisson distribution (where the variance equals mean) as $\theta_t$ becomes large. 
The negative binomial distribution may also accurately model a time series if there is a changing process mean within a time step: for example, if the mean of a Poisson distribution itself follows a gamma distribution, the resulting distribution is negative binomial. 
Negative binomial regression (in contrast to Poisson regression) can account for unobserved heterogeneity, time dependence in the rate of a process and contagion within a time step that all lead to overdispersion~\citep{barron1992analysis}.

An interpretation of the dispersion parameter for a time series model of counts is that events are $1 + \theta^{-1}$ times as ``crowded'' in time relative to a Poisson process with the same mean~\citep{lloyd1967mean} (see Supplemental Information). 
For example, $\theta = 1$ corresponds to a situation where the average number of infections in the same time step as a randomly selected case will exceed the Poisson expectation by a factor of two. 
In a simple example relevant to surge capacity in healthcare systems, $\theta = 1$ implies that a random infectious individual visiting the emergency department at a hospital would find it on average to be twice as crowded with other infectious individuals (infected by the same pathogen) than expected for a Poisson process with the same incidence rate.

In a sufficiently large host population, and when the infectious pathogen can be assumed to spread in nonoverlapping generations, the number of infections each generation is often modeled as
\begin{equation}
    I_{t+1} \sim NB(\mu_t = R_t I_t, \theta_t = I_t)
\end{equation}
where time-varying reproductive number $R_t$ gives the expected number of secondary infections aqcuired from an infected indivual at time $t$, and the generation time is set to 1 without loss of generality~\citep{kendall1949stochastic, bjornstad2002dynamics}. 
Setting $\theta_t = I_t$ arises from the assumption that individuals who acquire the infection at time $t$ form independent lineages with identically distributed local rate parameters.
In applications this model for $theta$ beomes $\theta_t = C_t / \rho_t$ where $C_t$ represents reported cases and $\rho$ the reporting rate, which relates reported cases to the true number of infections as $C_t = \rho_t I_t$.
However, this requires that susceptible depletion in one lineage does not affect another, that transmission rates are equal across lineages, and that reporting rates do not vary across lineages. 

In practice, these assumption will not often hold, and our aim in this paper is to develop, test and apply an alternative approach, which makes data-driven estimates of $\theta_t$, including identifying timepoints when $\theta$ is changing rapidly, which may help to reveal the impacts of heterogeneity in transmission, susceptibility, and reporting. 

\section*{Methods}
By definition incidence volatility is fast relative to broadscale epidemic dynamics. 
Consequently, in order to estimate incidence volatility we first model incidence at broad spatiotemporal scales using natural splines~\citep{perperoglou2019review}. To allow for diverse shapes in the broadscale epidemic dynamics, spline modeling is conducted in a moving window such that for each half of the window
\begin{equation}
  \log\left(\dfrac{\mu_t}{N}\right)  = \sum_{j=1}^J \beta_j^{(t)} h_j(t)
\end{equation}
where $N$ represents population size, $h_j(t)$ are basis functions, the degrees of freedom is equal to the number of knots $k$ for the natural spline, $J = k + d +1$, where $d$ is the degree of the polynomial, and $\beta_j^{(t)}$ are fitted parameters. The window has half-width $\Delta$, centered at $t$, i.e., extending from $t-\Delta$ to $t + \Delta$. 
The degrees of freedom (number of knots) to be used for the natural splines, and the width of the moving window will depend on the application.
Explaination of the specific choices we used for our application to COVID-19 cases in US counties is described below.

Modeling the underlying epidemic dynamics based on log-transformed incidence allows us to address the statistical effects of population size on the relationship between the mean and variance in count data, which would otherwise confound our analysis.
Specifically, since population size influences the mean and variance of case count data, it impacts dispersion in different-sized populations that are otherwise identical.
Accordingly, population size appears as an offset in our model of broad-scale incidence changes. That is,
\begin{equation}
  \log(\mu_t) = \sum_{j=1}^J \beta_j^{(t)} h_j(t) + \log(N) 
\end{equation}

The form of the probability mass function (PMF) for infections at a time step is:
\begin{equation}
  f_t(I) = \binom{I + \theta - 1}{I} {\left( \frac{\mu}{\mu + \theta} \right)}^I {\left( \frac{\theta}{\mu + \theta} \right)}^\theta
\end{equation}
where $\mu$ is estimated via the linear predictor outlined above. 

We estimate $\theta_t$ from observed incidence data using an iteratively reweighted least-squares (IRLS) procedure for mean estimation, combined with the optimize function in R, which uses a combination of golden section search and successive parabolic interpolation, to compute $\theta_t$. 
Specifically, within each time window, the spline model with an offset term was used to estimate a series of $\mu_s$ values for $s = t-\Delta$ to $s = t + \Delta$ via IRLS, as implemented in the \texttt{NBPSeq} R package~\citep{di2015nbpseq}. 
A single value of $\theta_t$ was then calculated for the entire time window by maximizing the likelihood function, which is based on the negative binomial probability mass function defined above.

In addition to fitting the model at each time step, we developed a likelihood-ratio test (LRT) to test the hypothesis that $\theta$ has changed at each time step. 
This test involves fitting and comparing two models: a null model (no $\theta$ change) and a two-part model (with a $\theta$ change). 
For the null model, a single $\theta$ value was fitted for the entire time window. 
For the $\theta$-change model, separate $\theta$ values were fitted for the left (from $t-\Delta$ to $t$) and right (from $t$ to $t + \Delta$) halves of the time window.

Very large $\theta$ values correspond to processes that are operationally identical to a Poisson process. 
Accordingly, the test does not produce a $p$-value if any of the three $\theta$ estimates exceed a user-specified threshold. 
In the application below, we set this threshold at $10^3$, meaning that $\theta$ estimates with temporal crowding within $0.1\%$ of that expected for a Poisson process were considered effectively Poisson.

Similarly, values of $\theta$ very close to 0 focus all of the mass of the PMF on 0, representing a scenario where the probability of observing any infections approaches zero. As with the Poisson-like tolerance described in the previous paragraph, our algorithm does not produce a $p$-value if any of the three $\theta$ estimates are below a user-specified threshold. This threshold will depend on the presence of contiguous sections of the time series being analyzed during which no cases are observed. In the application below, we set this threshold to $10^{-3}$, because $\theta$ values below this level correspond to 0 frequencies that greatly exceed those in the data.

With both upper and lower $\theta$ thresholds--—corresponding to Poisson-like and zero tolerances, respectively—--maximum likelihood estimates (MLEs) of $\theta$ beyond these thresholds exhibited unbounded behavior. When $\theta$ exceeded the upper threshold, corresponding to processes operationally identical to a Poisson process, the MLE tended to grow arbitrarily large, with the likelihood function reaching its maximum at the upper boundary of the calculated domain. Conversely, when $\theta$ fell below the lower threshold, representing extreme overdispersion with probability mass concentrated near zero, the MLE approached zero, and the likelihood function peaked at the lower boundary of the domain. This behavior reflects the inability of the model to reliably estimate $\theta$ when it lies outside the specified thresholds (Fig. 1c).

\subsection*{Application to simulated data}
We evaluated the robustness of our framework to a range of population sizes, magnitudes of dispersion changes, and shapes of underlying incidence trends by generating 2,000 simulated epidemic curves with known parameters. 
Epidemic trends were modeled as smoothed incidence series derived from 16-week sections randomly selected from US COVID-19 data (described below), scaled to reflect different population sizes ranging from $10^3$ to $10^7$. 
For each simulated trajectory, dispersion parameters ($\theta_1$ and $\theta_2$) were assigned to the two halves of the selected 16-week window, and case counts were simulated using a negative binomial distribution, where the mean ($\mu$) was based on the smoothed incidence trend scaled by the population size. 
The values of $\theta_1$ and $\theta_2$ were drawn from a uniform distribution spanning $10^{-2}$ to $10^{2}$, with 10\% of simulations set to have no change in dispersion ($\theta_1 = \theta_2$). 
Extremely large differences in dispersion (absolute log-ratio $>3$) were capped by setting $\theta_2 = \theta_1$. 

\subsection*{Application to empirical data}
We applied our framework to COVID-19 case data for the United States at the administrative level of counties, compiled by The New York Times, based on reports from state and local health agencies between Jan 4, 2020, and March 18, 2023~\citep{nytimes_covid19_2021}, and using county population sizes estimated for 2021 from the United States Census Bureau~\citep{us_census_county_estimates_2021}.
Cumulative cases for the largest three counties in each state were converted to weekly counts by keeping the last observation from each week and differencing to compute new cases. Occasionally, reported cumulative case counts were not monotonically increasing due to corrections posted by local agencies as they resolved incoming data. 
As a result, approximately 0.24\% of estimated new cases across all counties in the dataset were negative and these were set to zero. 
For each county, we analyzed overlapping 16-week windows, shifting one week (i.e., one timestep) at a time. 
Within each window, the framework estimated the dispersion parameter ($\theta$) using a natural spline with three degrees of freedom for each half of the window to model the broad-scale trend in incidence. 
Outputs included estimated dispersion parameters ($\theta_1$, $\theta_2$, for the left and right halves of each window, and $\theta$ for the entire window), likelihood ratio test statistics, $p$-values for changes in dispersion at the midpoint of the window, and flags for boundary conditions such as failure to reject Poisson-like dispersion or collapse to extreme overdispersion.

\section*{Results and Discussion}

Simulations indicate that the LRT framework accurately detects changes in dispersion, with p-values converging to 0.5 as the effect size approaches 0, reflecting the uniform distribution of p-values under the null hypothesis, and decreasing toward zero as the effect size increases (Fig.~\ref{fig1}). The framework is also robust to the range of population sizes present in the empirical data—county populations ranged from approximately 48 thousand to 9.9 million, and we tested the framework on simulated populations between 10 thousand and 10 million. Across this range, the method produced accurate estimates for $\theta$ within $10^{-2} \leq \theta \leq 10^2$, encompassing all operationally relevant values for COVID-19 incidence data and many other infectious diseases. Lower values would concentrate the probability mass function (PMF) for cases almost entirely on 0, while higher values effectively correspond to a Poisson distribution.

\clearpage
\begin{figure}[!ht]
\includegraphics[width=1\textwidth]{fig1}
\caption{
Detecting dispersion changes in case count time series. 
a: Weekly incidence of COVID-19 in the United States, with time measured in weeks since January 4, 2020, showing an example of a randomly-selected 16 week period used as an incidence trend when in simulation-based validation of the LRT test (red). 
b: Cases in in one county (Douglas County, Nebraska) over the sample time period with estimated incidence trend (red) and estimated dispersion values on either side of the midpoint. 
c: Estimated $\theta$ versus true $\theta$ in simulation studies combining a randomly-selected section of the national incidence curve with a random population size and set of dispersion values. Estimated values outside of tolerance plotted in purple (close to Poisson) and blue (close to collapsing to zero). 
d: Statistical power of the LRT test.}\label{fig1}
\end{figure}
\clearpage


Applying the method to COVID-19 cases in US counties enabled investigation of changes in dispersion in relation to both observed trends and model expectations (Figure~\ref{fig2}).  
Periods of increased case count variability corresponded with decreases in $\theta$, indicating that dispersion was dynamic. 
Changes in dispersion exhibited both expected and unexpected patterns of variation relative to standard theory.  
In some instances, $\theta$ varied inversely with incidence, consistent with standard epidemic theory, while in other periods, deviations from this expectation occurred, potentially signaling shifts in underlying transmission dynamics.  
Notably, significant changes in the dispersion parameter were observed during major epidemic transitions, such as the surge at the beginning of 2022, and at the end of the time series, when the pandemic was transitioning toward endemicity as the landscape of susceptibility was evolving~\citep{lavine2021immunological}.  
The landscape of susceptibility was evolving as a larger proportion of cases involved reinfections.  
These findings underscore the complex behavior of the dispersion parameter, which not only varied with changes in case count regimes but also revealed departures from the model expectations described by Eq.~1, which are consistent with changes in the underlying drivers of transmission. 

Highly overdispersed patterns were observed for many of the examined counties more frequently later in time series, consistent with more heterogeneity in transmission, susceptibility and reporting. 
In addition, there are increases in dispersion around the peaks in incidence (Figure~\ref{fig3}).
Evidence for a change in \begin{math}\theta\end{math} was observed across many counties (evidenced by a concentration of low p-values around peak incidence) (Fig\ 3 f). Note that these p-values should be corrected for multiple testing when used for inference instead of visualization.
Raising variance relative to mean (higher dispersion) implies spatiotemporal "crowding" of cases (i.e. localized surges) which may necessitate more surge capacity in hospitals and testing centers. 
It appears that there are more surges on the way up to, and on the way down from, peak incidence, some of which departs from the dispersion expected under standard epidemic theory. 
This indicates less diffuse epidemic dynamics that are potentially more subject to climate forcing \cite{dalziel_urbanization_2018}, and increased locally experienced mean density \cite{lloyd_mean_1967} at unexpected points in the COVID-19 pandemic. 

\clearpage
\begin{figure}[!ht]
\includegraphics[width=1\textwidth]{fig2}
\caption{Dispersion analysis of weekly COVID-19 case data for Jefferson County, Alabama. 
Results for all counties are shown in Figure 3  %.~\ref{fig3}.  
a: Weekly reported COVID-19 incidence.  
b: Estimated dispersion parameter ($\theta$) over time.  
c: Comparison of estimated dispersion (gray) with predicted values from the standard model $\theta_{t+1} = C_t / \rho_t$, where $C_t$ is reported cases and $\rho_t$ is the reporting rate. Predictions are shown for fixed $\rho_t = 0.1$ (black) and $\rho_t = 0.9$ (blue), chosen to encompass the range of $\theta$ expected under variable $\rho$.  
d: Likelihood ratio test (LRT) statistic over time. Statistically significant changes in dispersion (red) correspond to p-values below the Bonferroni-corrected 5\% threshold of a chi-square distribution with one degree of freedom.  
}\label{fig2}
\end{figure}
\clearpage

\section*{Acknowledgments}
RA work on this project was supported by X and Y. BDD work on this project was supported by the National Science Foundation (NSF) grants (X, Y) and by the David and Lucile Packard Foundation.

\clearpage
\section*{References}
\bibliographystyle{vancouver} 
\bibliography{references} 

% End Document
\end{document}
